{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk7eDm0UvuV4"
      },
      "source": [
        "# Transform Your Documents into AI-Ready Data with Docling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 1: Document Conversion\n",
        "\n",
        "Welcome to the first lab in our comprehensive Docling workshop series! This three-part journey will take you from document processing basics to building cutting-edge, transparent AI systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview: What You'll Build\n",
        "\n",
        "In this first lab, you'll learn how to transform complex documents into AI-ready structured data. But this isn't just about extraction - it's about intelligent conversion that preserves everything important for downstream AI applications.\n",
        "\n",
        "### By the End of This Lab\n",
        "\n",
        "You'll have mastered:\n",
        "- **Document Loading**: Ingesting PDFs, Word docs, PowerPoints, and more\n",
        "- **Structure Extraction**: Preserving hierarchy and relationships\n",
        "- **Table Excellence**: Converting complex tables into usable formats\n",
        "- **Image Handling**: Extracting and preparing images for AI processing\n",
        "- **Metadata Preservation**: Maintaining information needed for visual grounding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "**[Docling](https://docling-project.github.io/docling/)** is an open-source toolkit for document processing, parsing, and conversion designed for generative AI applications.\n",
        "\n",
        "### Key Features\n",
        "- **Multi-format support**: PDF, DOCX, XLSX, HTML, images, and more\n",
        "- **Advanced PDF understanding**: Page layout, reading order, table structure, code blocks, formulas\n",
        "- **Unified DoclingDocument representation**: Consistent data structure across all formats\n",
        "- **Flexible export options**: Markdown, HTML, JSON, DocTags\n",
        "- **Local execution**: Process sensitive data without external services\n",
        "- **Framework integration**: LangChain, LlamaIndex, and other AI frameworks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why we use Docling for Document Conversion\n",
        "\n",
        "Data is the foundation for all AI systems. In order to leverage as much data as possible, we need to be able to ingest data of various formats with accuracy. Howver, LLM's typically requre data in a specific format, thus the need for conversion.\n",
        "\n",
        "**Without proper conversion**:\n",
        "- Information gets lost or jumbled\n",
        "- Tables become unreadable text\n",
        "- Images disappear entirely\n",
        "- Document structure is destroyed\n",
        "\n",
        "**With Docling's advanced conversion**:\n",
        "- Every piece of information is preserved\n",
        "- Tables maintain their structure\n",
        "- Images are extracted and processable\n",
        "- Layout and relationships are understood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhPuTXE5laO7"
      },
      "source": [
        "### Basic Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "U4UTqpiL8Dfe",
        "outputId": "e111d023-bae6-4548-8fb3-be1958c60107"
      },
      "outputs": [],
      "source": [
        "! pip install \"docling[vlm]\" matplotlib pillow pandas python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV-71yke857S"
      },
      "source": [
        "### Import Essential Components\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eg9Lln_89Cv"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Core Docling imports\n",
        "from docling.document_converter import DocumentConverter\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
        "from docling.document_converter import PdfFormatOption\n",
        "\n",
        "# For advanced features\n",
        "from docling_core.types.doc import ImageRefMode, PictureItem, TableItem, TextItem, DoclingDocument\n",
        "\n",
        "# For data processing and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create output directory\n",
        "output_dir = Path(\"output\")\n",
        "output_dir.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N0cmabF_Ria"
      },
      "source": [
        "## Basic Document Conversion\n",
        "\n",
        "### Minimal Example\n",
        "\n",
        "The simplest way to convert a document:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjeZWdaMQq3j"
      },
      "outputs": [],
      "source": [
        "# example document: Docling Technical Report\n",
        "docling_paper = \"https://arxiv.org/pdf/2501.17887\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRBIgujl_01F",
        "outputId": "cc3cb054-fd05-47d2-a5af-d00b48c20b67"
      },
      "outputs": [],
      "source": [
        "# Simple conversion\n",
        "\n",
        "# Create a converter instance\n",
        "converter = DocumentConverter()\n",
        "\n",
        "# Convert a document\n",
        "result = converter.convert(docling_paper)\n",
        "doc = result.document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-OlC5yvlaO7",
        "outputId": "381d699b-bd99-4587-9d6a-616cb3915cb5"
      },
      "outputs": [],
      "source": [
        "# Export to Markdown\n",
        "md_out = doc.export_to_markdown()\n",
        "\n",
        "# printing an excerpt\n",
        "print(f\"{md_out[:2000]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxDEG2s-lSLq"
      },
      "source": [
        "### Document Structure Exploration\n",
        "\n",
        "One of Docling's superpowers is understanding document structure. This becomes critical in Lab 2 (chunking) and Lab 3 (visual grounding).\n",
        "\n",
        "Let's explore what Docling discovers:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJv614U1lS1x",
        "outputId": "1b7d46bf-0fd3-42c5-c72a-ad316d7e11dc"
      },
      "outputs": [],
      "source": [
        "# Document metadata - important for tracking\n",
        "print(f\"Document title: {doc.name}\")\n",
        "print(f\"Number of pages: {len(doc.pages)}\")\n",
        "print(f\"Number of tables: {len(doc.tables)}\")\n",
        "print(f\"Number of pictures: {len(doc.pictures)}\")\n",
        "\n",
        "# Explore the document structure\n",
        "print(\"\\nDocument structure:\")\n",
        "for i, (item, level) in enumerate(doc.iterate_items()):\n",
        "    if i < 10:  # Show first 10 items\n",
        "        item_type = type(item).__name__\n",
        "        text_preview = item.text[:200] if hasattr(item, 'text') else 'N/A'\n",
        "        print(f\"{'  ' * level}{item_type}: {text_preview}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrrwFDxmHsbz"
      },
      "source": [
        "## Export Formats and Options\n",
        "\n",
        "Docling supports multiple export formats with various options:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiCbsd1ifnns"
      },
      "outputs": [],
      "source": [
        "# Export to different formats (various options available, but called with default ones)\n",
        "markdown_text = doc.export_to_markdown()\n",
        "html_text = doc.export_to_html()\n",
        "json_dict = doc.export_to_dict()\n",
        "doc_tags = doc.export_to_doctags()\n",
        "\n",
        "# Save different formats (various options available, some shown)\n",
        "doc.save_as_markdown(\n",
        "    output_dir / \"document.md\",\n",
        "    image_mode=ImageRefMode.PLACEHOLDER,\n",
        "    image_placeholder=\"<!-- my image placeholder -->\",\n",
        "    # ...\n",
        ")\n",
        "\n",
        "# ...\n",
        "\n",
        "# Export as JSON\n",
        "doc.save_as_json(\n",
        "    output_dir / \"document.json\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HoHUwTRlwMF"
      },
      "source": [
        "## Working with Tables\n",
        "\n",
        "Docling provides excellent table extraction capabilities, for this example, let's use a document with more tables, found [here](https://midwestfoodbank.org/images/AR_2020_WEB2.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qyW1roXzD_E"
      },
      "source": [
        "## Image and Figure Extraction\n",
        "\n",
        "Docling also provides image extraction capabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBJvmt1tlaO8"
      },
      "outputs": [],
      "source": [
        "# example document with tables\n",
        "tables_example = \"https://arxiv.org/pdf/2502.09927\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iSBDPf_f4gb",
        "outputId": "6028ed2c-5641-4ea2-894f-8d42bd607b05"
      },
      "outputs": [],
      "source": [
        "# Convert a document with tables\n",
        "table_result = converter.convert(tables_example)\n",
        "table_doc = table_result.document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD7k7Sg_laO8",
        "outputId": "eea71290-ff3f-49af-d427-613e96a45692"
      },
      "outputs": [],
      "source": [
        "print(f\"\\nDocument contains {len(table_doc.tables)} tables\")\n",
        "\n",
        "# Export all tables\n",
        "for table_idx, table in enumerate(table_doc.tables):\n",
        "    # Convert to pandas DataFrame\n",
        "    df = table.export_to_dataframe()\n",
        "\n",
        "    print(f\"\\n## Table {table_idx}\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    display(df.head())\n",
        "\n",
        "    # Save as CSV\n",
        "    df.to_csv(output_dir / f\"table_{table_idx}.csv\", index=False)\n",
        "\n",
        "    # Save as HTML\n",
        "    with open(output_dir / f\"table_{table_idx}.html\", \"w\") as fp:\n",
        "        fp.write(table.export_to_html(doc=table_doc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tCfJxhHaIRR"
      },
      "source": [
        "## Image and Figure Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EANW0BKX0Q25"
      },
      "source": [
        "### Extracting and Visualizing Page Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNDC06dGaH5M",
        "outputId": "fc27a03f-d8b0-4282-9eb8-b4b4bc014cbb"
      },
      "outputs": [],
      "source": [
        "# Configure pipeline to extract images\n",
        "IMAGE_RESOLUTION_SCALE = 2.0  # 2x resolution (144 DPI)\n",
        "\n",
        "pipeline_options = PdfPipelineOptions(\n",
        "    images_scale=IMAGE_RESOLUTION_SCALE,\n",
        "    generate_page_images=True,\n",
        "    generate_picture_images=True,\n",
        ")\n",
        "\n",
        "converter_with_images = DocumentConverter(\n",
        "    format_options={\n",
        "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
        "    }\n",
        ")\n",
        "\n",
        "# Convert with image extraction\n",
        "img_result = converter_with_images.convert(docling_paper)\n",
        "img_doc = img_result.document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVhQ9MSWlaO8",
        "outputId": "24308bf5-7020-48e0-992c-ce01c0102a5a"
      },
      "outputs": [],
      "source": [
        "# Create images subdirectory\n",
        "images_dir = output_dir / \"images\"\n",
        "images_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Save page images\n",
        "for page_no, page in img_doc.pages.items():\n",
        "    page_image_filename = images_dir / f\"page_{page_no}.png\"\n",
        "    with page_image_filename.open(\"wb\") as fp:\n",
        "        page.image.pil_image.save(fp, format=\"PNG\")\n",
        "\n",
        "print(f\"Saved {len(img_doc.pages)} page images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmfwcH_uUKkp"
      },
      "source": [
        "### Extract Figures and Tables as Images\n",
        "\n",
        "For custom processing, we can also extract figures and tables as images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmxxCUVHUKTl",
        "outputId": "e73d0748-eebf-4614-8fcc-e7a84ca25c71"
      },
      "outputs": [],
      "source": [
        "# Extract all figures and tables as separate images\n",
        "table_counter = 0\n",
        "picture_counter = 0\n",
        "\n",
        "for element, level in img_doc.iterate_items():\n",
        "    if isinstance(element, TableItem):\n",
        "        table_counter += 1\n",
        "        image_filename = images_dir / f\"table_{table_counter}.png\"\n",
        "        with image_filename.open(\"wb\") as fp:\n",
        "            element.get_image(img_doc).save(fp, \"PNG\")\n",
        "\n",
        "    elif isinstance(element, PictureItem):\n",
        "        picture_counter += 1\n",
        "        image_filename = images_dir / f\"figure_{picture_counter}.png\"\n",
        "        with image_filename.open(\"wb\") as fp:\n",
        "            element.get_image(img_doc).save(fp, \"PNG\")\n",
        "\n",
        "print(f\"Extracted {table_counter} tables and {picture_counter} figures as images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pxfi8azdLTQ"
      },
      "source": [
        "### Inspecting Picture Content\n",
        "\n",
        "Docling will automatically preserve captions and extract text content from extracted images. Let's take a look at what is extracted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia--zHY9dNQc",
        "outputId": "4c950171-48e4-43e8-f283-0d84c9a206b7"
      },
      "outputs": [],
      "source": [
        "def inspect_pictures_with_images(doc: DoclingDocument, image_size=(6, 4)):\n",
        "    \"\"\"Display pictures inline with their text content\"\"\"\n",
        "    for idx, picture in enumerate(doc.pictures):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Picture {idx}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Display the image\n",
        "        try:\n",
        "            img = picture.get_image(doc)\n",
        "            if img:\n",
        "                plt.figure(figsize=image_size)\n",
        "                plt.imshow(img)\n",
        "                plt.axis('off')\n",
        "                plt.title(f\"Picture {idx}\")\n",
        "                plt.show()\n",
        "        except Exception as e:\n",
        "            print(f\"Could not display image: {e}\")\n",
        "\n",
        "        # Display metadata\n",
        "        caption = picture.caption_text(doc)\n",
        "        if caption:\n",
        "            print(f\"\\nCaption: {caption}\")\n",
        "\n",
        "        if hasattr(picture, 'prov') and picture.prov:\n",
        "            print(f\"Location: Page {picture.prov[0].page_no}\")\n",
        "\n",
        "        # Display embedded text\n",
        "        print(\"\\nEmbedded text elements:\")\n",
        "        text_found = False\n",
        "        for item, level in doc.iterate_items(root=picture, traverse_pictures=True):\n",
        "            if isinstance(item, TextItem):\n",
        "                print(f\"{'  ' * (level + 1)}- {item.text}\")\n",
        "                text_found = True\n",
        "\n",
        "        if not text_found:\n",
        "            print(\"  (No text elements found)\")\n",
        "\n",
        "# Use the simple inline display\n",
        "inspect_pictures_with_images(img_doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hjtRz-mq1Id"
      },
      "source": [
        "### Visualizing Document Layout with Bounding Boxes\n",
        "\n",
        "In order to understand how each part of the document is extracted, let's visualize the extracted elements.\n",
        "\n",
        "We can do that by using one of Docling's built-in visualizers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt_xLM4blaO8",
        "outputId": "ff8d949d-5264-4002-cff3-9b3d6ab5821a"
      },
      "outputs": [],
      "source": [
        "from docling_core.transforms.visualizer.layout_visualizer import LayoutVisualizer\n",
        "\n",
        "layout_visualizer = LayoutVisualizer()\n",
        "page_images = layout_visualizer.get_visualization(doc=img_doc)\n",
        "\n",
        "num_pages_to_viz = 2  # first N pages to visualize\n",
        "pages_to_viz = list(page_images.keys())[:num_pages_to_viz]\n",
        "for page in pages_to_viz:\n",
        "    display(page_images[page])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkBT1FFUwzYN"
      },
      "source": [
        "## Advanced Features: Enrichment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDM-OeUgy0ym"
      },
      "source": [
        "### Picture Classification and Description\n",
        "\n",
        "Beyond basic captioning capabilities, Docling is also able to process images using multimodal LLM's. This will give us more indepth picture descriptions to help us leverage image data more effectively.\n",
        "\n",
        "Let's try this with the integrated granite-vision model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the following blocks for running the models within Docling, or skip to the next ones for using the models within Ollama (or other model providers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4ba3a486c40d4b39ae7c4bb6c004b440"
          ]
        },
        "id": "WXMHPBTdDkev",
        "outputId": "5c21974b-e704-44bb-b0c8-6a6cedfdaaab"
      },
      "outputs": [],
      "source": [
        "from docling.datamodel.pipeline_options import PictureDescriptionVlmOptions\n",
        "\n",
        "# Configure enrichment pipeline\n",
        "enrichment_options = PdfPipelineOptions(\n",
        "    do_picture_description=True,\n",
        "    picture_description_options=PictureDescriptionVlmOptions(  # model & prompt choice\n",
        "        repo_id=\"ibm-granite/granite-vision-3.1-2b-preview\",\n",
        "        prompt=\"Give a detailed description of what is depicted in the image\",\n",
        "    ),\n",
        "    generate_picture_images=True,\n",
        "    images_scale=1.0,\n",
        ")\n",
        "\n",
        "converter_enriched = DocumentConverter(\n",
        "    format_options={\n",
        "        InputFormat.PDF: PdfFormatOption(pipeline_options=enrichment_options)\n",
        "    }\n",
        ")\n",
        "\n",
        "enr_result = converter_enriched.convert(docling_paper)\n",
        "enr_doc = enr_result.document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUVWwmcq4SJE",
        "outputId": "374020e2-a78e-488f-a74f-b1c3eb288541"
      },
      "outputs": [],
      "source": [
        "from docling_core.types.doc.document import PictureDescriptionData\n",
        "from IPython import display\n",
        "\n",
        "html_buffer = []\n",
        "# display the first 5 pictures and their captions and annotations:\n",
        "for pic in enr_doc.pictures[:5]:\n",
        "    html_item = (\n",
        "        f\"<h3>Picture <code>{pic.self_ref}</code></h3>\"\n",
        "        f'<img src=\"{pic.image.uri!s}\" /><br />'\n",
        "        f\"<h4>Caption</h4>{pic.caption_text(doc=doc)}<br />\"\n",
        "    )\n",
        "    for annotation in pic.annotations:\n",
        "        if not isinstance(annotation, PictureDescriptionData):\n",
        "            continue\n",
        "        html_item += (\n",
        "            f\"<h4>Annotations ({annotation.provenance})</h4>{annotation.text}<br />\\n\"\n",
        "        )\n",
        "    html_buffer.append(html_item)\n",
        "display.HTML(\"<hr />\".join(html_buffer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this blocks we use the models using an OpenAI-compatible API like Ollama."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from docling.datamodel.pipeline_options import PictureDescriptionApiOptions\n",
        "\n",
        "# Configure enrichment pipeline\n",
        "enrichment_options = PdfPipelineOptions(\n",
        "    do_picture_description=True,\n",
        "    enable_remote_services = True,\n",
        "    picture_description_options=PictureDescriptionApiOptions(\n",
        "        url=\"http://localhost:11434/v1/chat/completions\",\n",
        "        params={\n",
        "            \"model\": \"granite3.2-vision:2b\",\n",
        "            \"max_completion_tokens\": 200,\n",
        "        },\n",
        "        prompt=\"Give a detailed description of what is depicted in the image\",\n",
        "        timeout=60,\n",
        "    ),\n",
        "    generate_picture_images=True,\n",
        "    images_scale=1.0,\n",
        ")\n",
        "\n",
        "converter_enriched = DocumentConverter(\n",
        "    format_options={\n",
        "        InputFormat.PDF: PdfFormatOption(pipeline_options=enrichment_options)\n",
        "    }\n",
        ")\n",
        "\n",
        "enr_result = converter_enriched.convert(docling_paper)\n",
        "enr_doc = enr_result.document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from docling_core.types.doc.document import PictureDescriptionData\n",
        "from IPython import display\n",
        "\n",
        "html_buffer = []\n",
        "# display the first 5 pictures and their captions and annotations:\n",
        "for pic in enr_doc.pictures[:5]:\n",
        "    html_item = (\n",
        "        f\"<h3>Picture <code>{pic.self_ref}</code></h3>\"\n",
        "        f'<img src=\"{pic.image.uri!s}\" /><br />'\n",
        "        f\"<h4>Caption</h4>{pic.caption_text(doc=doc)}<br />\"\n",
        "    )\n",
        "    for annotation in pic.annotations:\n",
        "        if not isinstance(annotation, PictureDescriptionData):\n",
        "            continue\n",
        "        html_item += (\n",
        "            f\"<h4>Annotations</h4>{annotation.text}<br />\\n\"\n",
        "        )\n",
        "    html_buffer.append(html_item)\n",
        "display.HTML(\"<hr />\".join(html_buffer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae4hX3N30sHd"
      },
      "source": [
        "## Visual Language Models (VLMs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1t3ou824ngR"
      },
      "source": [
        "### Using SmolDocling\n",
        "\n",
        "[SmolDocling](https://huggingface.co/ds4sd/SmolDocling-256M-preview) is a compact (256M parameters) vision-language model for document conversion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yE_0sWVl06hs",
        "outputId": "bdda3da4-7484-49ff-ccda-270a28d659d2"
      },
      "outputs": [],
      "source": [
        "import platform\n",
        "from docling.datamodel.pipeline_options import (  # Additional imports for VLM\n",
        "    VlmPipelineOptions,\n",
        "    smoldocling_vlm_conversion_options,\n",
        "    smoldocling_vlm_mlx_conversion_options,\n",
        ")\n",
        "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
        "\n",
        "if (\n",
        "    \"darwin\" in platform.system().lower()\n",
        "    and \"arm64\" in platform.machine().lower()\n",
        "):  # optimized for Apple Silicon (MLX)\n",
        "    vlm_options = smoldocling_vlm_mlx_conversion_options\n",
        "else:\n",
        "    vlm_options = smoldocling_vlm_conversion_options\n",
        "\n",
        "vlm_pipeline_options = VlmPipelineOptions(\n",
        "    force_backend_text=False,\n",
        "    vlm_options=vlm_options,\n",
        ")\n",
        "\n",
        "converter_vlm = DocumentConverter(\n",
        "    format_options={\n",
        "        InputFormat.PDF: PdfFormatOption(\n",
        "            pipeline_options=vlm_pipeline_options,\n",
        "            pipeline_cls=VlmPipeline,\n",
        "        )\n",
        "    }\n",
        ")\n",
        "\n",
        "vlm_result = converter_vlm.convert(docling_paper)\n",
        "vlm_doc = vlm_result.document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc3tSGr9laO_",
        "outputId": "8d28edea-1076-4d1e-a3ff-c1bee96d9d23"
      },
      "outputs": [],
      "source": [
        "vlm_md_out = vlm_doc.export_to_markdown()\n",
        "\n",
        "# printing an excerpt\n",
        "print(f\"{vlm_md_out[:2000]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UStdCE9f1RgJ"
      },
      "source": [
        "## Summary and Next Steps\n",
        "\n",
        "### What You've Accomplished in Lab 1\n",
        "\n",
        "Congratulations! You've mastered the critical first step in document AI:\n",
        "\n",
        "- Basic and advanced document conversion with visual feedback\n",
        "- Multiple export formats with visualization options\n",
        "- Table and image extraction with visual verification\n",
        "- Enrichment models and VLMs\n",
        "\n",
        "### Your Journey Continues\n",
        "\n",
        "You're now ready for:\n",
        "- **Lab 2**: Learn intelligent chunking strategies to optimize for retrieval\n",
        "- **Lab 3**: Build a complete multimodal RAG system with visual grounding\n",
        "\n",
        "For more information:\n",
        "- GitHub: https://github.com/docling-project/docling\n",
        "- Documentation: https://docling-project.github.io/docling/\n",
        "- Technical Report: https://arxiv.org/abs/2408.09869\n",
        "- Examples: https://github.com/docling-project/docling/tree/main/examples"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
